{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estonian word embeddings\n",
    "\n",
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text # Estonian lemmatization\n",
    "from estnltk.corpus_processing.parse_enc import parse_enc_file_iterator # corpora parsing\n",
    "from gensim.models import Word2Vec # main model\n",
    "from gensim.models import KeyedVectors # for loading pre-trained models\n",
    "from pathlib import Path # operating system independent file paths\n",
    "from platform import python_version\n",
    "import tempfile # for saving model\n",
    "import pickle # for serializing the corpora\n",
    "print(python_version()) # Should be 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpora\\etnc19_balanced_corpus.vert\n",
      "corpora\\etnc19_doaj.vert\n"
     ]
    }
   ],
   "source": [
    "#https://metashare.ut.ee/repository/browse/estonian-national-corpus-2019-vrt-format/be71121e733b11eaa6e4005056b4002483e6e5cdf35343e595e6ba4576d839fb/\n",
    "#NB!!! .VERT files, not .PREVERT\n",
    "\n",
    "#Place all .vert files to be trained in the folder `corpora`\n",
    "corpora_path = Path('./corpora')\n",
    "\n",
    "corpora_names = []\n",
    "\n",
    "for filename in corpora_path.glob('*.vert'):\n",
    "    print(filename)\n",
    "    corpora_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpora\\etnc19_doaj.vert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#################################################################| 10793527/10793527 [15:09<00:00, 11869.69line/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8014367\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/corpus_processing/importing_text_objects_from_corpora.ipynb\n",
    "\n",
    "for i in range(len(corpora_names)):\n",
    "    # input file\n",
    "    input_file = corpora_names[i]\n",
    "    print(\"Reading corpora file\", input_file)\n",
    "\n",
    "    all_lemmas = []\n",
    "\n",
    "    # iterate over corpus and extract Text objects one-by-one\n",
    "    for text in parse_enc_file_iterator(input_file, \n",
    "                                        tokenization=\"preserve_partially\", \n",
    "                                        line_progressbar='ascii',\n",
    "                                        restore_morph_analysis=True): #Add logger?\n",
    "\n",
    "        lemmas = text.original_morph_analysis.lemma\n",
    "        all_lemmas.extend([lemma[0] for lemma in lemmas if lemma[0] != None])\n",
    "\n",
    "\n",
    "print(len(all_lemmas))\n",
    "print(all_lemmas.count(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all lemmas in a pickled file\n",
    "with open('corpora.pkl', 'wb') as f:\n",
    "    pickle.dump(all_lemmas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the corpora from the pickled file\n",
    "with open('corpora.pkl', 'rb') as f:\n",
    "    all_lemmas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Maybe that option won't work, let's see\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # input file\n",
    "        \n",
    "        for i in range(len(corpora_names)): # iterate over all corpora files\n",
    "            input_file = corpora_names[i]\n",
    "            print(\"Reading corpora file\", input_file)\n",
    "\n",
    "            # iterate over corpus and extract Text objects one-by-one\n",
    "            for text in parse_enc_file_iterator(input_file, \n",
    "                                                tokenization=\"preserve_partially\", \n",
    "                                                line_progressbar='ascii',\n",
    "                                                restore_morph_analysis=True): #Add logger?\n",
    "\n",
    "                #[['Mustam채e'], ['체hiselamu'], ...\n",
    "                lemmas = text.original_morph_analysis.lemma\n",
    "\n",
    "                #Filter out nonexisting (None) lemmas\n",
    "                # Mustam채e\n",
    "                doc_lemmas = [x[0] for x in lemmas if x[0] != None]\n",
    "\n",
    "                yield doc_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "model = Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:utils.py:551: saving Word2Vec object under models/word2vec.model, separately None\n",
      "INFO:utils.py:657: not storing attribute vectors_norm\n",
      "INFO:utils.py:657: not storing attribute cum_table\n",
      "INFO:utils.py:565: saved models/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/word2vec.model\") # for some reason I could not get pathlib to work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.6329436 , -4.2133846 ,  0.16787282,  4.0586267 ,  1.5857413 ,\n",
       "        0.68046236,  3.3129284 , -2.5557702 , -1.3165423 ,  3.172179  ,\n",
       "       -0.34429678,  0.8267788 , -0.9596452 , -0.48876774,  2.5859125 ,\n",
       "        2.1190176 ,  3.011986  ,  1.5091019 , -1.0206378 ,  0.45206624,\n",
       "        5.0228815 , -2.29621   , -0.24138844,  1.0629926 ,  1.3579892 ,\n",
       "        0.92665577, -4.411577  , -0.7759427 ,  3.4071152 , -0.64127296,\n",
       "       -3.215266  , -1.6152894 ,  1.1413366 , -0.82576925,  1.8092237 ,\n",
       "       -4.341474  , -1.7522033 , -2.0108278 ,  1.575736  ,  4.101202  ,\n",
       "        3.3476107 ,  3.9264216 , -3.0812013 , -4.7063084 ,  2.5465696 ,\n",
       "       -0.75586706,  1.7816662 ,  2.1636212 ,  2.0037787 , -6.004615  ,\n",
       "       -1.7273428 , -0.28177536,  1.062909  , -1.6998087 , -0.21927491,\n",
       "        0.27253053,  1.9296978 ,  0.1006563 , -1.7084851 , -2.089545  ,\n",
       "        1.7609588 ,  2.919195  ,  2.726189  ,  1.3555702 , -1.9165683 ,\n",
       "       -2.7238922 , -0.07057456, -0.62147635,  2.9888675 ,  3.467036  ,\n",
       "       -1.5003519 , -1.541207  , -1.9384276 , -5.2731767 ,  0.23668596,\n",
       "        0.501602  , -3.5418246 , -0.82698846, -0.9237639 , -3.6169143 ,\n",
       "        0.5153642 ,  1.3612468 ,  0.7221486 ,  2.2372584 ,  1.8296882 ,\n",
       "       -1.4003024 , -0.6773688 , -1.7706916 ,  3.4771693 , -2.040628  ,\n",
       "        5.29158   , -1.804989  ,  0.6051433 , -0.12464118,  1.6052656 ,\n",
       "        1.906256  , -0.6883118 ,  1.7760779 , -0.7907955 , -1.3413274 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['Tallinn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:utils.py:431: loading Word2Vec object from model_doaj_5ep\n",
      "INFO:utils.py:465: loading wv recursively from model_doaj_5ep.wv.* with mmap=None\n",
      "INFO:utils.py:503: setting ignored attribute vectors_norm to None\n",
      "INFO:utils.py:465: loading vocabulary recursively from model_doaj_5ep.vocabulary.* with mmap=None\n",
      "INFO:utils.py:465: loading trainables recursively from model_doaj_5ep.trainables.* with mmap=None\n",
      "INFO:utils.py:503: setting ignored attribute cum_table to None\n",
      "INFO:utils.py:437: loaded model_doaj_5ep\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[',', '.', 'olema', 'ja', ')', '(', 'see', ':', '-', '\"']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(\"model_doaj_5ep\")\n",
    "\n",
    "#Most common lemmas\n",
    "model.wv.index2entity[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kollane', 0.9136537313461304),\n",
       " ('must', 0.8914934396743774),\n",
       " ('valge', 0.8838784694671631),\n",
       " ('천is', 0.8835828304290771),\n",
       " ('hall', 0.866241455078125),\n",
       " ('punane', 0.8651580810546875),\n",
       " ('roheline', 0.8572124242782593),\n",
       " ('pruun', 0.8451236486434937),\n",
       " ('luik', 0.8428295850753784),\n",
       " ('vares', 0.8385834693908691)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"sinine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
